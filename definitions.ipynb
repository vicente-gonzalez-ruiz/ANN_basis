{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN basis\n",
    "\n",
    "A neural network will have (https://medium.datadriveninvestor.com/neural-network-simplified-c28b6614add4)\n",
    "\n",
    "1. Input layer $x$, with the bias unit which is 1. It is also referred as the intercept.\n",
    "2. Weights associated with each connection, organized in layers $w_l$.\n",
    "3. One or more hidden layers, each hidden layer will have a bias unit $b_l$.\n",
    "4. Output layer.\n",
    "5. Activation function $\\phi$ which converts an input signal of a node to an output signal.\n",
    "    \n",
    "Weights are how neural networks learn. We adjust the weights to determine the strength of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron\n",
    "\n",
    "An entity that usually holds (outputs) a real number between $[0, 1]$. It can have one or more inputs multiplied by a vector of weights $w=\\{w_i\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{rcl}\n",
    " a^{(1)} & = & x \\\\\n",
    " z^{(l+1)} & = & a^{(l)}w^{(l)} + b^{(l)} \\\\\n",
    " a^{(l+1)} & = & \\sigma(z^{(l+1)}) \n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "where $x=\\{x_i\\}=a^{(0)}$ is the input activation pattern, $a^{(l)}$ the activation pattern of the $l$-th layer, and $\\sigma$ is the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function\n",
    "\n",
    "A function that impose some kind of non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation:\n",
    "\n",
    "Back propagation is a fast algorithm for learning. It tells us how the cost function will change when we change the weights and biases. Without going into the detailed mathematics for backward propagation. In back propagation, we compute the partial derivative of the cost with respect to weight and partial derivative of the cost with respect to biases for each training example. Average the partial derivatives over all the training examples.\n",
    "\n",
    "For our single data point, we determine the amount each of the weights and biases was responsible for the error. Based on how the weights are responsible for error, we adjust the all weights simultaneously.\n",
    "\n",
    "Weights can be updated once for all of the training data using Batch gradient descent (GD) or once for each of the training example using Stochastic gradient descent (SGD).\n",
    "\n",
    "Epoch is when the complete dataset is used once for learning, one forward propagation and one backward propagation for all training example. We repeat the forward and backward propagation for multiple epochs till we converge to a global minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (set)\n",
    "\n",
    "The use of the forward and back propagation over the training dataset that allows the the ANN to minimize the cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation (set)\n",
    "\n",
    "When training, the error is computed using the validation set, not the training set. The training and the validation sets are disjunct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (set)\n",
    "\n",
    "After training, the performance of the ANN is measured using the testing set, which must be different from the training and the validation sets. We should consider that, in general, the test data could not be available when we are training the ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference/prediction\n",
    "\n",
    "A forward propagation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch\n",
    "\n",
    "A pass through the entire set one time. Notice that in (B)GD, an epoch runs a batch, and in SGD an epoch runs over all the mini-batches once time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is learning rate?\n",
    "\n",
    "Learning rate controls how much we should adjust the weights with respect to the loss gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization techniques (regularized networks)\n",
    "\n",
    "A general name for all those techniques (L2 regularization, L1 regularization, dropout, and artificially increasing the training set size) that prevent overfitting. Regularized networks are constrained to build relatively simple models based on patterns seen often in the training data, and are resistant to learning peculiarities of the noise in the training data. Regularization only affects to weights, not biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting (overtraining)\n",
    "\n",
    "(Undesired) Specialization of the ANN in the training set. Thus, when we evaluate the ANN over the validation set, even if for the training set the error decreases, the error for the validation set increases. In general, if we see that the accuracy on the validation data is no longer improving, then we should stop training. In general, increasing the amount of training data is one way of reducing overfitting (regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Minimizes overfitting by ignoring some neurons when the ANN is trained, at random for each training element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropConnect\n",
    "\n",
    "The same concept that dropout, but used on the weights instead of the neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping (hyperparameter)\n",
    "\n",
    "One of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. Notice that the validation sep should be used to decide when to stop. Once the classification accuracy on the validation_data has saturated, we stop training. This strategy is called early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting the number of hidden units in each layer or limiting network depth\n",
    "\n",
    "Another simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight decay (regularization technique)\n",
    "\n",
    "A simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights (L1 norm) or squared magnitude (L2 norm) of the weight vector, to the error at each neuron. Intuitively, the effect of regularization is to make it so the network prefers to learn small weights, all other things being equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Error function\n",
    "\n",
    "Measure the error of the ANN of a single input. For example, the squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "Measure the error of the ANN for a input set. For example, the mean squared error. Notice that not always we deal with errors, but with entropies of the output, such as the cross-entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation\n",
    "\n",
    "The output of the neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight\n",
    "\n",
    "The relationship between to neurons in adaject layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias\n",
    "\n",
    "The minimal activation level needed to fire up the neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Batch) Gradient Descend ((B)GD)\n",
    "\n",
    "We want to minimize:\n",
    "\n",
    "\\begin{equation}\n",
    "  Q(w) = \\frac{1}{n}\\sum_{i=1}^n Q_i(w)\n",
    "\\end{equation}\n",
    "\n",
    "where $w$ is the parameter (or set of parameters) that we want to found, $n$ is the number of points where $Q$ is evaluated, and $Q_i$ are positive. With (B)GD, we iterate:\n",
    "\n",
    "\\begin{equation}\n",
    "  w := w - \\eta \\nabla Q(w) = w - \\frac{\\eta}{n} \\sum_{i=1}^n \\nabla Q_i(w)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta$ is the *step* or *learning rate*, and $\\nabla Q(w)$ represents the gradient of $Q(w)$. Notice that we must compute the gradient for each $i$-th observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Identical to (B)GD, but only a subset of the observations (called mini-batch, and that could be only one) is used in each iteration (update step). Notice that, unlike (B)GD, a smaller number of gradients have to be computed. However, in this case the value $\\nabla Q(w)$ is only an approximation of the computed by (B)GD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Convolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a visual cortex. In a CNN one or more hidden layers include layers that perform convolutions. In a 2D-CNN, the input $x$ is a tensor with a shape (number of inputs) x (input height) x (input width) x (input channels). After passing through a convolutional layer, the image becomes abstracted to a feature map with shape (number of inputs) x (feature map height) x (feature map width) x (feature map channels). Conceptually, each convolutional neuron processes data only for its receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture. The layers of a CNN have neurons arranged in 3 dimensions: width, height and depth (number of feature detectors).\n",
    "\n",
    "A difference to ANNs, CNNs provides:\n",
    "\n",
    "1. Invariance to translation (when an image is rotated, sized differently or viewed in different illumination an object will be recognized as the same object).\n",
    "2. A convolutional layer contains units whose receptive fields cover a patch of the previous layer. Thus, a much smaller number of weights for a given dimesion of an stimuly. Convolution reduces the number of free parameters, allowing the network to be deeper, and avoids the vanishing gradients and exploding gradients problems seen during backpropagation in traditional neural networks.\n",
    "3. Furthermore, convolutional neural networks are ideal for data with a grid-like topology (such as images) as spatial relations between separate features are taken into account during convolution and/or pooling.\n",
    "4. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron's receptive field.\n",
    "5. Except when using dilated layers, in sucessive convolutional layer, each neuron takes input from a larger area in the input than previous layers.\n",
    "6. All neurons of a hidder layer share the same weights and bias. In other words, for the $(j,k)$-th (hidden) neuron of a convolutional layer (using a filter size of 5x5), we compute:\n",
    "\\begin{equation}\n",
    "  \\sigma(\\sum_{l=0}^{4}\\sum_{m=0}^{4}w_{l,m}a_{j+l, k+m} + b)\n",
    "\\end{equation}\n",
    "where $w$ are the (matrix) weights, $a$ is the activation of the previous layer, and $b$ is the bias. This means that all the neurons in the first hidden layer detect exactly the same feature, just at different locations in the input image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel (filter)\n",
    "\n",
    "The $\\{w,b\\}$ (shared coefficients and shared bias) values of a convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Local) Receptive field (size, hyperparameter)\n",
    "Each neuron inside a convolutional layer is connected to only a small region (3x5x5 neurons, for example, considering a RGB image) of the layer before it, called a receptive field. CNNs use a receptive field-like layout in which each neuron receives connections only from a subset of neurons in the previous (lower) layer. The receptive field of a neuron in one of the lower layers encompasses only a small area of the image, while the receptive field of a neuron in subsequent (higher) layers involves a combination of receptive fields from several (but not all) neurons in the layer before (i. e. a neuron in a higher layer \"looks\" at a larger portion of the image than does a neuron in a lower layer). In this way, each successive layer is capable of learning increasingly abstract features of the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "The mathematical operation that helps compute similarity of two signals. Closely related to cross correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional layer\n",
    "\n",
    "The convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the filter entries and the input, producing a 2-dimensional activation map of that filter. As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.\n",
    "\n",
    "Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map.\n",
    "\n",
    "Three hyperparameters control the size of the output volume of the convolutional layer: the depth, stride and padding size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride length (hyperparameter)\n",
    "\n",
    "The number of neurons that there are between two adjacent receptive fields, that can be overlapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature detector (convolution(al) kernel/filter)\n",
    "\n",
    "The discrete signal that convolves the signal $a_l$ is defined by the vector of weights and the bias, and represent particular features of the input. Each neuron in a CNN computes an output value by applying a specific function to the input values received from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias. Learning consists of iteratively adjusting these biases and weights. The feature detected by a hidden neuron as the kind of input pattern that will cause the neuron to activate: it might be an edge in the image, for instance, or maybe some other type of shape. \n",
    "\n",
    "Stacking many convolutional layers leads to feature detectors that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature/Activation map\n",
    "\n",
    "The output of a convolutional layer $a_l$ for a given feature detector, and also the function computed by the combolutional layer for such detector. The set of activation maps stacked together over the depth dimension conforms the output volume of the convolutional layer. The depth dimension defines the number of feature maps generated by the convolutional layer. Each feature map is generated by a different kernel. Notice that each feature is detectable across the entire image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth\n",
    "\n",
    "The depth of the output volume of a convolutional layer controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input.  The number of neurons in a convolutional layer is proportional to the depth. Depth inside of the CNN can be considered as the RGB color domain at the input of the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride\n",
    "\n",
    "The step size used in the convolution. Controls the overlapping between the receptive fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "\n",
    "Sometimes, it is convenient to pad the input with zeros (or other values, such as the average of the region) on the border of the input volume. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume, this is commonly referred to as \"same\" padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poolling layer\n",
    "\n",
    "Prepared a condensed feature map, helping with “Translational Invariance”. Pooling is based on the concept that when we change the input by a small amount, the pooled outputs do not change. Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, tiling sizes such as 2 x 2 are commonly used. Global pooling acts on all the neurons of the feature map. There are two common types of pooling in popular use: max (max-polling) and average.\n",
    "\n",
    "The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting.\n",
    "\n",
    "Usually, polling does not operate along the depth dimension.\n",
    "\n",
    "In CNNs where the conectivity between adjacent layers is smaller than in normal ANNs. For this reason, stochastic pooling (based on a binomial distribution) usually replaces common dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function layer\n",
    "\n",
    "Usually, CNN neurons does not incorporate any activation function, which is provided by a specific layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected layer\n",
    "\n",
    "In clasiffication task, the last layers of a deep ANN structure are conformed by a common multilayer percetron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift equivariance\n",
    "\n",
    "All the neurons in a given convolutional layer respond to the same feature within their specific response to the input visual field. Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field, i.e. they grant translational equivariance - given that the layer has a stride of one.\n",
    "\n",
    "In addition to reducing the sizes of feature maps, the pooling operation grants a degree of local translational invariance to the features contained therein, allowing the CNN to be more robust to variations in their positions.\n",
    "\n",
    "Parameter sharing contributes to the translation invariance of the CNN architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "In data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
